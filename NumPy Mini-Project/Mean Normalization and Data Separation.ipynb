{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "#### Trung Ng\n",
    "\n",
    "----------------------------------------------------\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, (1000, 20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2431.421 2369.013 2506.119 2557.359 2525.366 2424.275 2555.758 2580.932\n",
      " 2524.247 2464.656 2492.975 2619.58  2560.204 2551.055 2482.234 2470.991\n",
      " 2542.546 2493.005 2509.98  2544.714]\n",
      "[1459.90296587 1457.90639783 1435.56138108 1436.07232761 1481.79093331\n",
      " 1451.74333592 1423.82386391 1435.92957187 1462.23692061 1478.7432467\n",
      " 1432.13364543 1422.53443951 1440.09748225 1455.87786231 1439.97559398\n",
      " 1459.05297331 1429.36383888 1470.92930591 1433.37146114 1443.56091669]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "print(ave_cols)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = X - ave_cols.reshape((1, 20)) / std_cols.reshape((1, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1718.33453246 2149.37505823 4397.25425855 ... 1546.30514968\n",
      "  1076.24889774 3445.23719666]\n",
      " [1638.33453246 1243.37505823 1556.25425855 ... 4133.30514968\n",
      "  3471.24889774  951.23719666]\n",
      " [ 489.33453246 2870.37505823 3072.25425855 ... 3950.30514968\n",
      "  4755.24889774 3583.23719666]\n",
      " ...\n",
      " [2555.33453246  635.37505823  952.25425855 ...   22.30514968\n",
      "  1142.24889774 4718.23719666]\n",
      " [2788.33453246 3380.37505823  779.25425855 ...  792.30514968\n",
      "  4750.24889774 4134.23719666]\n",
      " [3294.33453246 4383.37505823 1755.25425855 ... 3830.30514968\n",
      "  1467.24889774  369.23719666]]\n",
      "2.3653142204769657\n",
      "4994.365314220478\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm)\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.mean(np.min(X_norm, axis=0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.mean(np.max(X_norm, axis=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "print(np.random.permutation(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[775 326 897 145 781 130 554 149 428 354 580  91 911 968 808  78 283 880\n",
      " 934 447 913 822 573 237 972 431 314 780 239 154 527 298 471 497 768 661\n",
      " 843 493 480 172 232 544 754  40 588  64  86 924 315  95 210 776 785 252\n",
      " 802 833  57 777 229 953 618 640 483 267 459 881 418 576   4 352 192 587\n",
      " 121 627 898 496  31  55 194 760 177 592 343 741 178 160 319  84 596   5\n",
      " 854 753 362 917 905 955 762 690 286 989 360 857 159  74 285 831 879 219\n",
      " 757 948  11 240 426  61  88 637 106 675 608 146 528 650 585 441 184  77\n",
      "  36 827 395  23  18 558 803 280 358 823 796 681 814 589 932 478 330 415\n",
      " 818 782 505 129 891 944 817 499 919 770 494 724 519 988 852 429  17 751\n",
      " 402 137 208 138 979 509 866 369 908 864 976 696 481 270 135 526 151 357\n",
      "  48 736 368 188 477 749 521 226 906 718 867 702 982  54 861 570 297 634\n",
      " 127 313 694 810  47 767   6 439 830 639 176  41 243 747 875 222 886 937\n",
      " 617 709 539 567  26 946 251 469 113 654 421 205 986 712 918 645 788 855\n",
      " 234 301 950 501 502 931 963 805 420  13 216  80 845 698 511 209 396 193\n",
      " 744 379 655 874 449 321  66 309 263 430 287 853 564 579 662 907 657 424\n",
      " 436 175 378 446 278 341 970 281 977 105 302 456 465 475 928 327 450 486\n",
      " 666 355 344 624 401 255 203 348 605 383 520  94  62 404 930 885  22 870\n",
      " 490 181 545 399 613 489 179 165 942 719 316 828  87 985 530 894 660 553\n",
      " 437 425 386 199  16 716 514 644 628 910 535 190 765 583 228 504 876 300\n",
      " 317 407 274  79 578 800 708 902 846 374 397 935 858 863 792 276 772 107\n",
      " 487 685 848 647 606 333 849 359 812 460 325 938 871 524 248 485 679 253\n",
      " 470 981 969 888 832 721 260 723 488 847  46 965 653 170 967 156 998 643\n",
      " 773 180 400 896 414 546 148  19 651  98 677 966 250 687 143 214 766 813\n",
      " 462 312 597 678 126 482 590 629 715 865 726 361 413 515 337 599 120 119\n",
      " 364 422 795 614 380 602 978 631 841 684 235 363 824 652 851 438  24 697\n",
      " 213 904 936 117 332 733 442 108 626 264 742 951 971 713 206  60 738 277\n",
      " 729  70 625 889 883 728 804 821 435 584 756 225 811 303 568 551 220 324\n",
      " 339 444 914 793 484  37 569 183 197 356 549 290  42 200 594 174 114 809\n",
      " 711 231 246 163 840 731 819 916 542 943 249  21  76 258 669 334 365  59\n",
      " 601 257 815 171  92 223 582 458 534 784 522 537  29 941 412 370 445 122\n",
      " 195 207 296  67 816 990 173 350 468 266  10 725 778 118 961 769 293 152\n",
      " 463 571 730 331 329 820 406 347 598 623 443 557 574 474 455 658 895 141\n",
      " 899  51 996 926 789 307 109 739 518 791 349 714 112 764 467 101  58 227\n",
      " 410 909 722  27 826 890  83 294 403  34 664 763 218 533 922 115 615 638\n",
      " 320 244 616 394 464 351 168 516 375 732 405 479 116 161 233 915 929 167\n",
      " 676 745 224 196 282 688 975  71 869 288 663 147 201 409 593  89 735 140\n",
      " 771 621 604 221 595 513 872 659 461 997 947 801 956 692 323  38 295  72\n",
      " 153 103 686 211 962 434 612 158 682 774 565 247 382  39 124 111 887  85\n",
      " 799 836 901 541  65 556 945 839   2 185 204 665 656 373 136 182 451 844\n",
      " 680 959 635 532 366 381 304 543 920 139 507 893 269 633 292 619 572 491\n",
      " 275 648 954 336 387 984 671 254 705 611 923 142 123 717 562 133  99  35\n",
      " 419  56 892 162 759 829  49  53 873 779 622 186 577 238 540 241   0 632\n",
      " 392 100 448 272  81 525 668 510 806 991 995 311 555 376 306 273 289 860\n",
      " 807 850 706 755 783 957 794 134 649 674 933 949 217 198 164 586 672 508\n",
      " 903 345 202 215 563 500 457 423 642 104 367 673 758 110  73 921 699 727\n",
      " 371   9 346 498 189 512   8 882 958 305 102 547 279 641 925 670 342 503\n",
      " 432 862 411 877 452 835 495 552  33 610 144 737 878 566 912 856  50 389\n",
      "  12 408 454 691 748 245 391  69  14 994 868  45 704 603 695 987 761 786\n",
      " 308  63 150 607 636  82 230  97 398   3 859 743 999 707 560 427 310 693\n",
      " 561  25 453 384  68 559 191 798 740 155 385  75 256  20 131 128 689 417\n",
      "  43  28   7 646 388 973 734 939   1 609 630 536 750 261 600 340 271 746\n",
      " 517 550 268  93 531 259 703 440 575  32 472 242 837 548 710 372 466 335\n",
      " 166  90 790 884 683 838 322 212 476  15 353 390 825 992  44 125 169 842\n",
      " 720 393 620 492 964 284 927 338 262 377 993 752 299 328  96 974 797 667\n",
      " 581 834  30 416 433 591 523 236 900 701 952 787 318 983 529 265 157 291\n",
      " 132 980 187 473  52 960 940 700 506 538]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "800\n",
      "-200\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "train_set_range = int(X_norm.shape[0] * 0.6)\n",
    "valid_set_start_index = train_set_range\n",
    "print(valid_set_start_index)\n",
    "valid_set_end_index = valid_set_start_index + int(X_norm.shape[0] * 0.2)\n",
    "print(valid_set_end_index)\n",
    "test_set_start_index = valid_set_end_index - X_norm.shape[0]\n",
    "print(test_set_start_index)\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[0:train_set_range, :]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[valid_set_start_index:valid_set_end_index, :]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[test_set_start_index:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
